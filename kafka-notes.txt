kafka - Messaging Broker
  created at linkedin and opened source in 2011
  Jay krebbs created it in linkedin. Now CEO of confluent

  Kafka is 2 things
    server software - broker
    client api - java librar
      producer api
      consumer api

  Kafka connect
    source connector - pulls data from source system and sends to broker
    sink connector - pulls data and sends to external system 

    create a kafka connector - impl two java classes
      SourceConnector() and SinkConnector()
      SourceTask() and SinkTask()

    architecture - fault tolerant and self-managed
      reliability, high availability, scalability, and load balancing

      worker
      connector
      class
  kafka broker (core)
  kafka client
  kafka streams
    is a library in java/scala for building applications or microservices
    Input data must be in kafka topic

    Data steams unbounded, infinite and ever growing, sequence of data in small packaets (kb)

    collect and store in a storage system
      database
      create one big job to database
        batch processing happens every one or two days. ( on a schedule )
      
      Stream processing is a continual process
  ksql
    sql interface to the kafka streams
      most things you do in streams are available to you with ksql'
    
    runs in 2 modes 
      cli mode - good for development
      headless

    Works in cluster

    grouping and aggregating on your kafka topics
    grouping and aggregating over a time window
    apply filters
    joins two topics
    sink the result of your query into another topic

highly scalable and distributed platform for creating and processing streams in real-time.

pub sub enterprise system architecture
  producer - client app that sends data records
  broker - recieves message from broker and stores in local storage
  consumer - client apps that reads messages from the broker and processes them

Kafka Core concepts 
  producer - needs producer application
    just a series of bytes
  consumer - application that recieves the data
    applications need permission to read the data
    request and recieve messages
  consumer groups - multiple consumers can share a message and handle the workload
  broker - just a kafka server
  cluster - group of computers acting together
  topic - unique name for a data streams (think of database table)
  partitions - breaks topics into different brokers within a cluster
    tool for scalability
  partition offset - unique seq id of a message. (immutable)
    topic name -> partition number -> offset number


Run Kafka Locally
  Apache Zookeeper - Datbase

  Kafka Producer/Consumer

  Brokers have configuration files
    server.properties - highly configurable

Kafka Storage Architecture
  Kafka Storage Architecture
  Kafka Cluster Architecture
  Work Distribution Architecture

  leader partitions
  follower partitions

Kafka Cluster
  Kafka is a masterless cluster. It is managed by Zookeeper

  Master broker - knows about all the brokers

  Zookeeper - manages nodes. 
    broker/ids/ - list of brokers in the cluster

  Single node is a broker and Zookeeper
    There is only one controller in the cluster

  Followers request messages from the leader
    ISR list (In Sync Replica)
      Not to far - <10

      commited vs uncommited messages
        commited - when messages are safely copied to the ISR
        uncommited - not safely copied to the isr. 

Kafka Producer API
  primary in java

  set config
  create producer
  send messages
  close producer
    if you dont close producer you will leak system resources